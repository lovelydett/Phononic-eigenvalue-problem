{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization,GRU,Reshape,UpSampling2D,Conv2DTranspose\n",
    "from keras.layers import Conv2D, GlobalMaxPooling1D, MaxPooling2D,Conv1D,MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "#from keras.utils.training_utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import csv\n",
    "import h5py\n",
    "import gc \n",
    "import argparse\n",
    "import os \n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model=Sequential()\n",
    "#     model.add(Dense(5120,input_dim=50,kernel_initializer='normal',activation='relu'))\n",
    "#     model.add(Dense(5120,kernel_initializer='normal',activation='relu'))\n",
    "#     model.add(GRU(5, input_shape=(None,50),activation='relu'))\n",
    "#     model.add(Dense(5120,kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "    model.add(Dense(29250,input_dim=50,kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Reshape((15,15,130)))\n",
    "    model.add(UpSampling2D(size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(130, (2,2), strides=1, padding='valid', data_format='channels_last', \n",
    "                              dilation_rate=1, activation=None, use_bias=True, kernel_initializer='uniform', \n",
    "                              bias_initializer='zeros'))\n",
    "    \n",
    "    model.add(UpSampling2D(size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(130, (2,2), strides=1, padding='valid', data_format='channels_last', \n",
    "                              dilation_rate=1, activation=None, use_bias=True, kernel_initializer='uniform', \n",
    "                              bias_initializer='zeros'))\n",
    "    \n",
    "    model.add(UpSampling2D(size=(2,2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(10, (2,2), strides=1, padding='valid', data_format='channels_last', \n",
    "                              dilation_rate=1, activation=None, use_bias=True, kernel_initializer='uniform', \n",
    "                              bias_initializer='zeros'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(4,4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense((1000),kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense((20480),kernel_initializer='normal',activation='relu'))\n",
    "    \n",
    "#     model.add(Conv1D(filters=2000, kernel_size = (5,) ,strides= 1,\n",
    "#                      input_shape=(50,1),kernel_initializer= 'uniform'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=(2,)))\n",
    "    \n",
    "#     model.add(Conv1D(filters=1000, kernel_size = (5,) ,strides= 1,\n",
    "#     input_shape=(50,1),kernel_initializer= 'uniform'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=(2,)))\n",
    "    \n",
    "    \n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(5120))\n",
    "#     model.add(Activation('relu'))\n",
    "    #model.add(Dense(5120, activation='linear'))\n",
    "    earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=60, verbose=2, mode='auto')\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 29250)             1491750   \n",
      "_________________________________________________________________\n",
      "reshape_20 (Reshape)         (None, 15, 15, 130)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_42 (UpSampling (None, 30, 30, 130)       0         \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 30, 30, 130)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_41 (Conv2DT (None, 31, 31, 130)       67730     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_43 (UpSampling (None, 62, 62, 130)       0         \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 62, 62, 130)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_42 (Conv2DT (None, 63, 63, 130)       67730     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_44 (UpSampling (None, 126, 126, 130)     0         \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 126, 126, 130)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_43 (Conv2DT (None, 127, 127, 10)      5210      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 31, 31, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 9610)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1000)              9611000   \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 20480)             20500480  \n",
      "=================================================================\n",
      "Total params: 31,743,900\n",
      "Trainable params: 31,743,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"MAE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just opposite as before, x here in the y in forward problem\n",
    "#and y here is the former x\n",
    "def get_train_data():\n",
    "    ds = h5py.File(\"../data/subData2D.h5\",\"r\")\n",
    "    \n",
    "    resolution = 64\n",
    "    \n",
    "    y_raw = ds[\"x0\"][:]\n",
    "    x_raw = ds[\"y0\"][:]\n",
    "    \n",
    "    # get x data\n",
    "    x_mean = np.mean(x_raw)\n",
    "    x_range = np.max(x_raw)-np.min(x_raw)\n",
    "    x_data = (x_raw-x_mean)/x_range\n",
    "    \n",
    "    x_data_2d = np.zeros((x_data.shape[0],5,10),dtype = x_data.dtype)\n",
    "#     #trasform x data into xxx*5*10 if CNN2D used\n",
    "#     for i in range(x_data.shape[0]):\n",
    "#         x_data_2d[i] = np.reshape(x_data[i],(5,10))\n",
    "\n",
    "    \n",
    "    # get y data\n",
    "    y_reduced = np.zeros((y_raw.shape[0],resolution,resolution,5),dtype=y_raw.dtype)\n",
    "    for i in range(resolution):\n",
    "        for j in range(resolution):\n",
    "            y_reduced[:,i,j] = y_raw[:,i*2,j*2]\n",
    "    \n",
    "    # y_reduced is now  xxx*32*32*5\n",
    "    y_mean = np.mean(y_reduced,axis = (0,1,2))\n",
    "    y_range = np.amax(y_reduced,axis=(0,1,2))-np.min(y_reduced,axis=(0,1,2))\n",
    "    y_data = (y_reduced-y_mean)/y_range\n",
    "    \n",
    "    # y_data needs to be flatten\n",
    "    y_flatten = np.zeros((y_data.shape[0],resolution*resolution*5),dtype = y_data.dtype)\n",
    "    for i in range(y_data.shape[0]):\n",
    "        y_flatten[i]=y_data[i].flatten()\n",
    "\n",
    "    return x_data,y_flatten,x_mean,x_range,y_mean,y_range\n",
    "    #return x_data_2d,y_flatten,x_mean,x_range,y_mean,y_range\n",
    "\n",
    "\n",
    "def generate_train_data(x_data,y_data,window_size,batch_size):\n",
    "    x_batch = np.zeros((batch_size,window_size)+(x_data[0].shape),dtype = x_data.dtype)\n",
    "    y_batch = np.zeros((batch_size,window_size)+(y_data[0].shape),dtype = y_data.dtype)\n",
    "    while 1:\n",
    "        count = 0\n",
    "        for i in range(x_data.shape[0]-window_size):\n",
    "            x_batch[count] = x_data[i:i+window_size]\n",
    "            y_batch[count] = y_data[i:i+window_size]\n",
    "            count+=1\n",
    "            if count == batch_size:\n",
    "                count = 0\n",
    "                yield(x_batch,y_batch)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_mean,x_range,y_mean,y_range = get_train_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15360, 50)\n",
      "(15360, 20480)\n"
     ]
    }
   ],
   "source": [
    "#x_train=x_train.reshape(x_train.shape+(1,))\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 360 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 91s 6ms/step - loss: 0.0786 - mean_absolute_error: 0.2405 - val_loss: 0.0774 - val_mean_absolute_error: 0.2391\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 91s 6ms/step - loss: 0.0783 - mean_absolute_error: 0.2399 - val_loss: 0.0773 - val_mean_absolute_error: 0.2387\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 91s 6ms/step - loss: 0.0782 - mean_absolute_error: 0.2396 - val_loss: 0.0775 - val_mean_absolute_error: 0.2394\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 91s 6ms/step - loss: 0.0779 - mean_absolute_error: 0.2391 - val_loss: 0.0774 - val_mean_absolute_error: 0.2397\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 91s 6ms/step - loss: 0.0776 - mean_absolute_error: 0.2385 - val_loss: 0.0770 - val_mean_absolute_error: 0.2377\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 91s 6ms/step - loss: 0.0776 - mean_absolute_error: 0.2385 - val_loss: 0.0764 - val_mean_absolute_error: 0.2371\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 91s 6ms/step - loss: 0.0773 - mean_absolute_error: 0.2379 - val_loss: 0.0763 - val_mean_absolute_error: 0.2368\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 91s 6ms/step - loss: 0.0772 - mean_absolute_error: 0.2377 - val_loss: 0.0775 - val_mean_absolute_error: 0.2370\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 91s 6ms/step - loss: 0.0771 - mean_absolute_error: 0.2374 - val_loss: 0.0766 - val_mean_absolute_error: 0.2369\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 91s 6ms/step - loss: 0.0770 - mean_absolute_error: 0.2372 - val_loss: 0.0766 - val_mean_absolute_error: 0.2374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53b8f849b0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit_generator(generate_train_data(x_train,y_train,5,60),\n",
    "#                     steps_per_epoch=256,epochs=3)\n",
    "x_val = x_train[15000:]\n",
    "y_val = y_train[15000:]\n",
    "model.fit(x_train[:15000],y_train[:15000],epochs=10, batch_size=30, verbose=1,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_inverse_15360_2Dct*3_e10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
