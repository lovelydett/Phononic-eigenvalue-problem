{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, GlobalMaxPooling1D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "#from keras.utils.training_utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import csv\n",
    "import h5py\n",
    "import gc \n",
    "import argparse\n",
    "import os \n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_units = 50\n",
    "n_convpool_layers = 1\n",
    "n_convlayers = 2\n",
    "n_reglayers = 2\n",
    "max_poolsize = (2,2)\n",
    "train_set_ratio = 0.7\n",
    "valid_set_ratio = 0.15\n",
    "set_split_ratio34 = 0.5\n",
    "drop_rate = 0.0\n",
    "n_filters = 130 #130 before \n",
    "reg_factor = 0.0\n",
    "kernel_size = (2,2)\n",
    "input_strides = 1\n",
    "kernel_init = 'uniform'\n",
    "cost_function = 'mean_squared_error'\n",
    "batch_size = 64#128\n",
    "feed_batch_size = 256\n",
    "input_sample_shape = [128,128,5]\n",
    "#target_sample_shape = [50]\n",
    "n_epochs = 35\n",
    "n_output = [0,50]\n",
    "n_set1 = 10000\n",
    "n_set2 = None\n",
    "n_set100 = 10000 \n",
    "n_post_test = 5000\n",
    "xnorm_axis = (0,1,2,3)\n",
    "early_stop_delta = 0.01 # 0.01 change or above is considered improvement\n",
    "early_stop_patience = 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_mean_n_range():\n",
    "    ds = ds = h5py.File(\"../data/data2D%d.h5\",\"r\",driver='family', memb_size=2500*10**6)\n",
    "    x_min = np.zeros((1,5),dtype = ds[\"random\"][\"x0\"].dtype)\n",
    "    x_max = np.zeros((1,5),dtype = ds[\"random\"][\"x0\"].dtype)\n",
    "    x_mean = np.zeros((1,5),dtype = ds[\"random\"][\"x0\"].dtype)\n",
    "    count = 0\n",
    "    for key1 in list(ds.keys()):\n",
    "        for key2 in ds[key1].keys():\n",
    "            if key2.find(\"x\")>=0 :\n",
    "                temp_x = ds[key1][key2][:]\n",
    "                if temp_x.shape[0] != 64:\n",
    "                    continue\n",
    "                    \n",
    "                #handle mean\n",
    "                count+=1\n",
    "                x_mean += np.mean(temp_x,axis=(0,1,2))\n",
    "                \n",
    "                #handle max\n",
    "                temp_max = np.amax(temp_x,axis=(0,1,2))\n",
    "                temp_batch = np.vstack([temp_max,x_max])\n",
    "                x_max = np.amax(temp_batch,axis=(0))\n",
    "                \n",
    "                #handle min\n",
    "                temp_min = np.amin(temp_x,axis =(0,1,2))\n",
    "                temp_batch = np.vstack([temp_min,x_min])\n",
    "                x_min = np.amin(temp_batch,axis=(0))\n",
    "                \n",
    "    x_mean = x_mean/count     \n",
    "    x_range = x_max-x_min\n",
    "    return x_mean,x_range\n",
    "\n",
    "def get_y_mean_n_range():\n",
    "    ds = ds = h5py.File(\"../data/data2D%d.h5\",\"r\",driver='family', memb_size=2500*10**6)\n",
    "    y_min = 0 \n",
    "    y_max = 0\n",
    "    y_mean = 0\n",
    "    count = 0\n",
    "    for key1 in list(ds.keys()):\n",
    "        for key2 in ds[key1].keys():\n",
    "            if key2.find(\"y\")>=0 :\n",
    "                temp_y = np.real(ds[key1][key2][:])\n",
    "                if temp_y.shape[0] != 64:\n",
    "                    continue\n",
    "                    \n",
    "                #handle mean\n",
    "                count+=1\n",
    "                y_mean += np.mean(temp_y)\n",
    "                \n",
    "                #handle max\n",
    "                temp_max = np.max(temp_y)\n",
    "                y_max = temp_max if temp_max>y_max else y_max\n",
    "                \n",
    "                #handle min\n",
    "                temp_min = np.min(temp_y)\n",
    "                y_min = temp_min if temp_min<y_min else y_min\n",
    "                \n",
    "    y_mean = y_mean/count     \n",
    "    y_range = y_max-y_min\n",
    "    return y_mean,y_range\n",
    "                \n",
    "def generate_data_from_file(x_mean,x_range,y_mean,y_range):\n",
    "    while 1:\n",
    "        ds = h5py.File(\"../data/data2D%d.h5\",\"r\",driver='family', memb_size=2500*10**6)\n",
    "        for key1 in list(ds.keys()):\n",
    "            x_count = 0\n",
    "            y_count = 0\n",
    "            for key2 in list(ds[key1].keys()):   #0-399 or 0-199\n",
    "                if key2[0]!=\"x\" or ds[key1][key2].shape[0]>64:\n",
    "                    continue\n",
    "\n",
    "                x_raw = ds[key1][key2][:]\n",
    "                y_key = \"y\"+key2[1:]\n",
    "                y_raw = ds[key1][y_key][:]\n",
    "\n",
    "        #                 x_mean = np.mean(x_raw,axis=(0,1,2))\n",
    "        #                 x_max = np.amax(x_raw,axis=(0,1,2))\n",
    "                x_normed = (x_raw-x_mean)/x_range\n",
    "                print(x_normed.shape)\n",
    "        #                 y_mean = np.mean(y_raw,axis=())\n",
    "        #                 y_max = np.max(y_raw,axis=())\n",
    "        #                 y_min = np.min(y_raw,axis=())\n",
    "                y_normed = (y_raw-y_mean)/y_range\n",
    "                print(y_normed.shape)\n",
    "\n",
    "                yield(x_normed,y_normed)\n",
    "def get_validation_data(x_mean,x_range,y_mean,y_range):\n",
    "    ds = h5py.File(\"../data/data2D%d.h5\",\"r\",driver='family', memb_size=2500*10**6)\n",
    "    x_val_raw = ds[\"random\"][\"x0\"][:]\n",
    "    y_val_raw = ds[\"random\"][\"y0\"][:]\n",
    "    \n",
    "#     x_val_mean = np.mean(x_val_raw,axis=(0,1,2))\n",
    "#     x_val_max = np.amax(x_val_raw,axis=(0,1,2))\n",
    "    x_val_normed = (x_val_raw-x_mean)/x_range\n",
    "    \n",
    "#     y_val_mean = np.mean(y_val_raw,axis=())\n",
    "#     y_val_max = np.max(y_val_raw,axis=())\n",
    "#     y_val_min = np.min(y_val_raw,axis=())\n",
    "    y_val_normed = (y_val_raw-y_mean)/y_range\n",
    "    \n",
    "    return x_val_normed,y_val_normed\n",
    "\n",
    "def get_test_data(x_mean,x_range,y_mean,y_range):\n",
    "    x_test_raw = np.load(\"../data/inputMatrix.npz\")[\"inputMatrix\"][:]\n",
    "    y_test_raw = np.load(\"../data/Solution.npz\")[\"frequency1\"][:,:50]\n",
    "    x_test = (x_test_raw-x_mean)/x_range\n",
    "    y_test = (y_test_raw-y_mean)/y_range\n",
    "    return x_test,y_test,x_test_raw,y_test_raw\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '../data/data2D0.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b383ba201b64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_mean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_x_mean_n_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-928d51bc820f>\u001b[0m in \u001b[0;36mget_x_mean_n_range\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_x_mean_n_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/data2D%d.h5\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'family'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemb_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2500\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mx_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"random\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"random\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mx_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"random\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ML\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '../data/data2D0.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "x_mean,x_range = get_x_mean_n_range()\n",
    "print(x_mean)\n",
    "print(x_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean,y_range = get_y_mean_n_range()\n",
    "print(y_mean)\n",
    "print(y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=n_filters, kernel_size = kernel_size ,strides= input_strides,\n",
    "                     input_shape=(128,128,5),kernel_initializer= kernel_init))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #model.add(Conv2D(filters=n_filters, kernel_size = kernel_size ,strides= input_strides,\n",
    "    #                 kernel_initializer= kernel_init))\n",
    "    #model.add(Activation('relu'))\n",
    "\n",
    "    #model.add(Conv2D(filters=n_filters, kernel_size = kernel_size ,strides= input_strides,\n",
    "    #                 kernel_initializer= kernel_init))\n",
    "    #model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=max_poolsize))\n",
    "\n",
    "    #model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=n_filters, kernel_size = kernel_size ,strides= input_strides,\n",
    "                     kernel_initializer= kernel_init))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=max_poolsize))\n",
    "\n",
    "    #model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=n_filters, kernel_size = kernel_size ,strides= input_strides,\n",
    "                     kernel_initializer= kernel_init))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=max_poolsize))\n",
    "    \n",
    "#     model.add(Conv2D(filters=n_filters, kernel_size = kernel_size ,strides= input_strides,\n",
    "#                      kernel_initializer= kernel_init))\n",
    "#     model.add(Activation('relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=max_poolsize))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n_hidden_units))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50, activation='linear'))\n",
    "\n",
    "    earlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=early_stop_delta, patience=early_stop_patience, verbose=2, mode='auto')\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(loss=cost_function, optimizer='adam', metrics=[\"MAE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val,y_val = get_validation_data(x_mean,x_range,y_mean,y_range)\n",
    "print(x_val.shape,y_val.shape)\n",
    "print(x_val[0][0][0])\n",
    "print(y_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generate_data_from_file(x_mean,x_range,y_mean,y_range),\n",
    "                    steps_per_epoch=999,epochs=12,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_wholeSet_normed_c3_f130_e10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test,x_test_raw,y_test_raw = get_test_data(x_mean,x_range,y_mean,y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step\n",
      "loss: 0.0013233348727226257\n",
      "mae: 0.03408118709921837\n"
     ]
    }
   ],
   "source": [
    "loss,mae=model.evaluate(x_test,y_test)\n",
    "print(\"loss:\",loss)\n",
    "print(\"mae:\",mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
